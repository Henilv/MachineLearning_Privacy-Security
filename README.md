# MachineLearning_Privacy-Security
ML: Adversarial FMNIST &amp; Machine Unlearning

Adversarial attacks are a class of attacks that show how ML has its flaws and the system can be spoofed.

Machine unlearning performs the task of deletion of datapoints from a trained model and the trade-off between accuracy and utility of such a model, this stems from gdpr regulation which lets users delete their data.
